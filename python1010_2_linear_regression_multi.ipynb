{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ee3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d56074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=np.array([[2,3],[3,2],[1,2],[-1,-2],[2,3],[3,4]])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3869d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=  np.array([\n",
    "    [4],\n",
    "    [-12],\n",
    "    [3],\n",
    "    [-11],\n",
    "    [-5],\n",
    "    [-17]\n",
    "])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63022f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w(x,y,w_,w_2,b_):\n",
    "    y_hat=w_*x.T[0]+w_2*x.T[1]+b_\n",
    "#     print(x.T[0],x.T[1])\n",
    "    n = len(x)\n",
    "    result1=0\n",
    "    result2=0\n",
    "    for x_i,y_i,y_hat_i in zip(x,y,y_hat):\n",
    "#         print(x_i[0],x_i[1],y_i,y_hat_i)\n",
    "        result1+=(y_i-y_hat_i)*x_i[0]\n",
    "        result2+=(y_i-y_hat_i)*x_i[1]\n",
    "    return [-1/(2*n)*result1,-1/(2*n)*result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58db42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([15.25]), array([16.91666667])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w(x_train,y_train,3,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9aecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_b(x,y,w_,w_2,b_):\n",
    "    y_hat=w_*x.T[0]+w_2*x.T[1]+b_\n",
    "    n = len(x)\n",
    "    result=0\n",
    "    for y_i,y_hat_i in zip(y,y_hat):\n",
    "        result+=(y_i-y_hat_i)\n",
    "    return -1/(2*n)*result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa894e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_b(x_train,y_train,3,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570bf6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,w_,w_2,b_):\n",
    "    y_hat=w_*x.T[0]+w_2*x.T[1]+b_\n",
    "    n=len(x)\n",
    "    result=0\n",
    "    for y_i,y_hat_i in zip(y,y_hat):\n",
    "        result+=(y_i - y_hat_i)**2\n",
    "    return (1/n)*result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(x_train,y_train,3,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787cfe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.81916667] [1.7925] [-1.07166667] [299.99189051]\n",
      "[-7.16378348] [4.96839112] [-4.33226715] [39.14172173]\n",
      "[-7.17497718] [4.97498659] [-4.32501489] [39.14166667]\n",
      "[-7.17499995] [4.97499997] [-4.32500003] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n",
      "[-7.175] [4.975] [-4.325] [39.14166667]\n"
     ]
    }
   ],
   "source": [
    "w_=3\n",
    "w_2=2\n",
    "b_=-1\n",
    "for i in range(50000):\n",
    "    dJ_dw=grad_w(x_train,y_train,w_,w_2,b_)\n",
    "    dJ_db=grad_b(x_train,y_train,w_,w_2,b_)\n",
    "    w_ = w_ - 0.01 * dJ_dw[0]\n",
    "    w_2 = w_2 - 0.01 * dJ_dw[1]\n",
    "    b_ = b_ - 0.01 * dJ_db\n",
    "    c_ = cost(x_train,y_train,w_,w_2,b_)\n",
    "    if i %5000==0:\n",
    "        print(w_,w_2,b_,c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostFunction(x,y,w,b):\n",
    "    cost = np.sum((((x.dot(w) + b) - y) ** 2) / (2*len(y)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [4],\n",
    "    [5],\n",
    "    [6],\n",
    "    [7]\n",
    "])#feature\n",
    "y=  np.array([\n",
    "    [4],\n",
    "    [-12],\n",
    "    [3],\n",
    "    [-11],\n",
    "    [-5],\n",
    "    [-17]\n",
    "])\n",
    "\n",
    "\n",
    "def cost_fn(y, y_hat, flag,x_=None):\n",
    "#     if flag:\n",
    "#         cost = -1/(2*len(y)) *  sum(x_*(y-y_hat))\n",
    "#     else:\n",
    "#         cost = -1/(2*len(y)) * sum(y-y_hat)\n",
    "    if flag:\n",
    "        cost = -(2/len(y)) *  sum(x_*(y-y_hat))\n",
    "    else:\n",
    "        cost = -(2/len(y)) * sum(y-y_hat)\n",
    "    return cost\n",
    "\n",
    "w=3\n",
    "b= -1\n",
    "lr =0.01\n",
    "for i in range(8000):\n",
    "    y_hat = w*x+ b\n",
    "    w= w - lr*cost_fn(y,y_hat,True,x)\n",
    "    b= b - lr*cost_fn(y,y_hat,False)\n",
    "    c_ = (1/len(y))*sum((y - y_hat)**2)\n",
    "    if i%1000==0:\n",
    "        print('w:',w, 'b:',b,'cost:',c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(self, x, y):\n",
    "    pred = x @ self.w + self.b  # predicted y-values\n",
    "    e = y - pred  # error term\n",
    "    return np.mean(e ** 2)  # mean squared error\n",
    "\n",
    "def fit(self, x, y):\n",
    "    pred = x @ self.w + self.b\n",
    "    e = y - pred\n",
    "    dJ_dw = (np.mean(e * (-2 * x), axis=0))  # partial derivate of J with respect to w\n",
    "    dJ_db = (np.mean(e * (-2), axis=0))  # partial derivate of J with respect to b\n",
    "    self.w = (self.w.T - self.lr * dJ_dw).T  # update w\n",
    "    self.b = self.b - self.lr * dJ_db  # update b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa914803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    return (x @ self.w.T + self.b)  # return predicted values\n",
    "def params(self):\n",
    "    return (self.w, self.b)  # return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f03dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([  # set x-values for regression line plot\n",
    "    [-3],\n",
    "    [10]\n",
    "])\n",
    "\n",
    "# Train model:\n",
    "model = LinearRegression(w=3, b=-1, lr=0.001)  # set initial parameters and learning rate\n",
    "\n",
    "for i in range(60000):  # set number of epochs\n",
    "    w_list.append(model.params()[0])  # append weights (=slopes) to list\n",
    "    b_list.append(model.params()[1])  # append biases (=y-intercepts) to list\n",
    "    c_list.append(model.cost(x_train, y_train))  # append costs to list\n",
    "    ys_list.append(model.predict(xs).T)  # append pairs of predicted y-values for xs\n",
    "    cl_list.append(model.predict(x_train).T)  # append predicted y-values for x_train to list\n",
    "    model.fit(x_train, y_train)  # fit model\n",
    "\n",
    "# print parameters and costs after all epochs\n",
    "print(\"weight: \" + str(model.params()[0]))\n",
    "print(\"y-intercept: \" + str(model.params()[1]))\n",
    "print(\"costs: \" + str(model.cost(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be776f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivatived_cost(y, y_hat, flag,x_=None):\n",
    "    if flag:\n",
    "        cost = -(2/len(y)) *  sum(x_*(y-y_hat))\n",
    "    else:\n",
    "        cost = -(2/len(y)) * sum(y-y_hat)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5727f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent(x, y, w, b, learning_rate, epochs):\n",
    "    cost_list = [0] * epochs\n",
    "   \n",
    "    for epoch in range(epochs):\n",
    "        z = x.dot(w) + b\n",
    "        loss = z - y\n",
    "        \n",
    "        weight_gradient = x.T.dot(loss) / len(y)\n",
    "        bias_gradient = np.sum(loss) / len(y)\n",
    "        \n",
    "        w = w - learning_rate*weight_gradient\n",
    "        b = b - learning_rate*bias_gradient\n",
    "  \n",
    "        cost = CostFunction(x, y, w, b)\n",
    "        cost_list[epoch] = cost\n",
    "        \n",
    "        if (epoch%(epochs/10)==0):\n",
    "            print(\"Cost is:\",cost)\n",
    "        \n",
    "    return w, b, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29812bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b,c=GradientDescent(Xtrain,Ytrain,np.zeros(Xtrain.shape[1]),0,0.02,epochs=15000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
